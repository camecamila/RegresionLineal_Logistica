---
title: "Final Estadistica II  | Cohorte 2021"
author: "Barbagelata, Camila Inés"
date: "Fecha de Entrega `r format(Sys.time(), '%d-%m-%Y')`"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

  <img src="C:/Users/cbarbagelata/OneDrive - Obra Social Acción Social de Empresarios Asociación Civil/Escritorio/Camila B/Estadistica II/Final/untref.jpg" width="250px">

</p>


```{r, echo=FALSE}
library (tidyverse)
library(ggpubr)
library(rstatix)
library(plyr)
library(dplyr)
library (kableExtra)
library(apa)
library(apaTables)
library(olsrr)#para hacer regresiones olsrr
library(gridExtra)
library(purrr)
library(tibble)
library(nortest)
library(goftest)
library(haven)
library(oddsratio)
library(MASS)
library(olsrr)
pacman::p_load(tidyverse,ggpubr,rstatix,plyr,pastecs,summarytools,RCurl,reshape2,pracma,raster,dplyr,gmodels,DescTools, haven, reshape2, Hmisc, olsrr, fastDummies)
```


* A lo largo del documento se presenta la resolución de los tres ejercicios que componen el final de Estadistica II

---

## Ejercicio 1. ANOVA  | Ejercicio pasteles

A partir de los datos brindados por el ejercicio se intenta resolver los siguientes puntos:

1. Existen diferencias estadísticamente significativas debidas al tipo de harina utilizada?

2. Existen diferencias estadísticamente significativas debidas al nivel de endulzamiento
utilizado?

3. Existe interacción estadísticamente significativa entre los factores considerados?

4. Realizar los gráficos de medias e interpretar.

Creacion de la base de datos (con variables factor)
```{r, echo=true}
azucar<-  factor(gl(4, 2, label=c("0", "50", "75", "100")))
harina <- rep (seq(1,2),12)
harina <- factor(harina, labels= c("General","Tortas"))
densidad <- c(0.9,0.91,0.86,0.88,0.93,0.86,0.79,0.86,0.87,0.9,0.89,0.82,0.88,0.85,0.82,0.85,0.9,0.8,0.91,0.83,0.87,0.8,0.8,0.85)
BasePasteles<- data.frame(azucar, harina, densidad)
BasePasteles
```
---

### Resolución

**Punto 1, 2, 3**. Existen diferencias estadísticamente significativas debidas al tipo de harina utilizada? Existen diferencias estadísticamente significativas debidas al nivel de endulzamiento
utilizado? Existe interacción estadísticamente significativa entre los factores considerados?

Dado que se desea analizar los efectos de dos factores distintos, que son el tipo de harina y el porcentaje de endulzamiento, sobre los atributos físicos de la torta, debemos aplicar el **metodo del analisis de varianza de dos factores**. 

Para su aplicacion resulta indispensable realizar un analisis descriptivo de los datos y el chequeo de los supuestos. 

A. Analisis descriptivo: Armado de tablas con resumenes estadisticos. 
```{r}
BasePasteles %>% group_by(azucar, harina) %>% get_summary_stats(densidad,type="mean_sd")
```
Observamos que las medias de densidad se asemejan entre los distintos grupos definidos por las dos variables factor, y aumenta en aquellas tortas con relizadas con una menor concentracion de azucar. 
Al observar los valores sd, notamos que las tortas realizadas con una concentracion de azucar al 100 tienen mayor homogeneidad. 

B. Chequeo de los requisitos para realizar anova de dos factores:

* Testeo de normalidad de las variables
```{r testeo de normalidad, echo=TRUE}
BasePasteles %>% group_by(harina, azucar) %>% shapiro_test(densidad)
```
Teniendo en cuenta que nuestra hipotesis nula es que los datos se distribuyen normalmente (H1= los datos no se distribuyen normalmente), se concluye que:

Los datos se distribuyen normalmente con excepcion del grupo definido por una concentracion 0 de azucar y con harina general y, aquellos grupos con 100 de azucar y harina de tortas. En estos dos grupos el valor de p es menor al nivel de significancia razonable (0,05). 

Dado que en la mayoria de los casos este supuesto de normalidad se cumple y teniendo en cuenta que no es un requisito muy estricto para realizar anova de dos factores, procedemos con el analisis.

* Testeo de homocedasticidad de varianzas
```{r}
BasePasteles %>% levene_test(densidad~ azucar*harina)
```
Nuestra hipotesis nula es que las varianzas son iguales (homocedasticidad), caso contrario las varianzas no son iguales (h1). 

A partir de los resultados (p = 0.88, por ende p>alfa) no rechazo Ho. Hay homocedasticidad, las varianzas son iguales para el nivel de significancia establecido. 

Una vez chequeados estos dos supuestos (normalidad y homocedasticidad), realizamos el analisis de varianza de dos factores. 

C. Prueba de interaccion entre los dos factores

```{r ANOVA DE DOS FACTORES SIN INTERACCION}
SinInteraccion <- aov(densidad ~ azucar+harina, data=BasePasteles)
summary(SinInteraccion)
```
A partir de los resultados (P>α) en ambas variables factor, concluimos que no existe diferencia significativa entre las medias de las densidades de las tortas en ninguno de los grupos definidos. 

```{r ANOVA DE DOS FACTORES CON INTERACCION}
ConInteraccion<- aov(densidad ~ azucar*harina, data=BasePasteles)
summary(ConInteraccion)
```

Dado que nuestra hipotesis nula (Ho) es que no existe interacción entre los dos factores, observando que P<α, se rechaza hipótesis nula. Se concluye que existe un efecto de interacción entre los dos factores, esto significa que, en presencia de un factor, el otro se comporta de manera diferente.  


**Respuesta - Conclusiones (pto 1, 2, 3)**: 
Resumiendos las conclusiones a las que llegamos hasta el momento:
* Existen diferencias debidas al tipo de harina utilizada, debidas al nivel de endulzamiento y debido a la interaccion entre los factores. 

**Punto 4** Realizar los gráficos de medias e interpretar. 

Para averiguar como se da la interaccion entre los factores, es decir, si la interaccion entre las dos variables tiene un efecto propio sobre el comportamiento de la variable dependiente o no.Para oberservar de que manera se da esta interaccion, realizamos un **grafico de interacción de medias** que en los casos de ausencia de interaccion se visualiza como dos rectas paralelos y si hay interaccion se entrecruzan: 

```{r grarico de interaccion}
with(BasePasteles, interaction.plot(azucar, harina, densidad, fun = mean, main = "Grafico de interaccion", xlab = "azúcar", ylab = "Densidad"))
```

La línea punteada corresponde a la harina general y la linea continua a la harina para tortas, en el eje horizontal encontramos las distintas concentracions de azucar y en el eje vertical las densidades. 

**Respuesta - Conclusiones (pto 4)**: 
Observamos que las tortas realizadas con harina general, su densidad aumenta pero cuando la concentracion de azucar supera el 75% cae marcadamente. En cambio, las tortas realizadas con harina para tortas se observa que la mayor densidad está dada por la menor concentración de azúcar reduciéndose a medida que ésta aumenta, volviendo a aumentar cuando se concentra al 100%. 

---

## Ejercicio 2. Regresión Lineal Multiple  | Ejercicio DETROIT

En un estudio que investiga el papel de las armas de fuego en el aumento de la tasa de homicidios de Detroit, se recogieron datos para los años 1961-1973. La variable de respuesta (la tasa de homicidios) y las variables potencialmente predictoras del comportamiento de ésta, se describen en el archivo p301.sav. 

Se requiere construir una ecuación de regresión que relacione la Tasa de Homicidios (variable H), con el resto de las variables disponibles, y determinar si estas variables son útiles para predecir la Tasa de Homicidios y tambien los siguientes puntos:

1.  Saber cuál es el nivel de asociación lineal de las variables predictoras con la variable H.

2.  Realizar una regresión lineal múltiple, seleccionando los mejores predictores entre las variables independientes disponibles, utilizando un método de selección automática. Describir el proceso de selección automática utilizado. (Sug. Considerar como probabilidad de entrada 0.10 y de salida del modelo 0.15). 

3.  Informar qué información da el coeficiente de determinación. 

4.  Reconocer cuáles son los supuestos necesarios para definir la prueba inferencial de los estimadores de los parámeros. 

5.  Analizar la bondad del ajuste del modelo obtenido, comentando los indicadores y/o test que considera.

6.  Realizar un análisis de los residuos del modelo para evaluar el cumplimiento de los supuestos. Para esto, realizar gráficos de los residuos con el valor predicho.

7.  Analizar la colinealidad de las variables predictoras presentes en la ecuación.

8.  Analizar la presencia de observaciones atípicas y/o influyentes.
 
Creacion de la base de datos: 
```{r cargamos BD, echo=TRUE}
BasePasteles <- read_sav("C:/Users/cbarbagelata/OneDrive - Obra Social Acción Social de Empresarios Asociación Civil/Escritorio/Camila B/Estadistica II/Final/p301.sav")
head(BasePasteles)
```
---

### Resolución
 
En este ejercicio se nos propone analizar si una serie de variables afectan el comportamiento de una variable dependiente. Para determinar en que medida las variables se constituyen como variables predictoras de la variable dependiente, debemos construir un modelo de regresion lineal multiple. 

**Punto 1** Nivel de asociación lineal de las variables predictoras con la variable H.

Para analizar en nivel de asociacion entre nuestra variable a predecir (H) y las posibles variables predictoras, una opcion es realizar gráficos de dispersion: 
 
```{r}
p301 <- BasePasteles[, 2:13]#Dado que la variable YEAR permite identificar cuando fueron recolectados los datos, actuando como un dato identificatorio, voy adejar de considerar esta variable para el analisis. 

#Grafico de dispersión: 
p301 %>%
  gather(-H,  key = "var", value = "value") %>% ggplot(aes(x = value,color= 'red',  y = H)) +
    geom_point() + facet_wrap(~ var, scales = "free") + theme_minimal()
```

**Respuesta - Conclusiones (pto 1)**: A partir de los graficos podemos observar si existe cierta asociacion entre las variables posibles predictoras y la variable dependiente. Tambien se puede ver como se da esta asociacion entre las variables.En algunos casos, las variables se relacionan de manera positiva, es decir que ambas variables aumentan conjuntamente (FTP, G, GR, HE, LIC, NMAN, WE, YEAR). En cambio, en otros casos se vinculan de manera negativa (CLEAR, W). 
Pero en dos graficos se observa que no existe correlacion entre las variables, este es el caso de la variable UNEMP y M.

**Punto 2** Regresión lineal múltiple

Para determinar en que medida las variables predictivas predicen el comportamiento de la variable h (la tasa de homicidios) aplico Análisis de Correlación de Pearson. Con este metodo obtenemos el Coeficiente de Correlación de Pearson (R) que de acuerdo a su  magnitud y su signo se puede ver la intensidad y el tipo asociacion entre las variables.

Primero debemos aplicar la funcion lm() para luego  aplicar ols_correlations y ver la correlacion de cada variable potencialmente predictora con la variable h

```{r Asociacion Lineal, echo=TRUE}
# Aplico lm()  
model <- lm(H ~ FTP + UNEMP + M + LIC + GR + CLEAR + W + NMAN + G + HE + WE, data = p301)
summary(model)
# Aplico ols que utiliza model que es la salida de lm 
ols_correlations(model)
```

Analisis de los resultados: 

* El valor de Zero Order indica la correlacion de cada variable independiente con la variable dependiente (h). La magnitud de de Zero Order  indica el nivel de asociacion y su signo señala el tipo de asociacion. Podemos concluir que:

* Aquellas variables con un coeficiente cercano a 0 poseen menor nivel de asociacion con la variable h (ej: UNEMP, M). 
* Aquellas variables con valores cercano a 1, indican una mayor correlacion entre las variables (ej: FTP, CLEAR, W, NMAN, G, HE, WE).
 
* Aquellas variables con un Zero Order de signo positivo indica que a valores altos de una variable corresponden valores altos de la otra. Es decir, ambas variables cambian en el mismo sentido.Esto confirma lo observado en el grafico de dispersion. 

* Aquellas variables con valores negativos cambian en sentido contrario, es decir, a valores altos de una variable corresponden valores bajos de la otra. 

Aplico metodo de seleccion automatica (con probabilidad de entrada 0.10 y de salida del modelo 0.15) que va a elegir dentro de las variables disponibles, aquellas que realicen un aporte estadísticamente significativo al modelo. De esta manera se construye un modelo en el que se evaluo cada variable que forma parte, dejando unicamente aquellas relevantes para predecir el comportamiento de la variable dependiente (tasa de homicidios). 

```{r}
ols_step_best_subset(model, pent = 0.10, prem = 0.15)
```

Esta funcion muestra los mejores modelos segun cantidad de variables. Para elegir el modelo es necesario evaluar los indicadores de cada uno (tanto R2 como R2 ajustado, como el Cp de Malows y el AIC). Tampoco debemos perder de vista el principio de parsimonia que sugiere seleccionar la menor cantidad de variables predictoras posibles. 

Es posible observar que nos arroja un modelo con una unica variable predictora (CLEAR) que explica la tasa de homicidios en mas de un 93%. Si bien en los modelos con mas variables predictoras el % aumenta, este aumento no es tan significativo. Esto de alguna manera indica que no es necesrio considerar muchas variables predictoras para conformar nuestro modelo. 

Voy a optar por el modelo que esta conformado por 3 variables predictoras (UNEMP, LIC y WE) que reduce los C de Mallows y los AIC y aumenta el r2 ajustado. 

```{r}
modelo_ejer2 <- lm( H ~ UNEMP +LIC+ WE ,
                    data = p301)

summary(modelo_ejer2)
```
**Respuesta - Conclusiones (pto 2)**:Al analizar este modelo, vemos que las variables incluidas son significativas para predecir el comportamiento de la variable dependiente (tasa de homicidios). 
De acuerdo a los valores que muestra la tabla, podemos concluir que el comportamiento de las variables predictoras respecto de la variable dependiente se da de la siguiente manera: Cuando la variable UNEMP aumenta una unidad, la tasa de hominicios aumenta en 1.43. 
Este modelo explica en un 99,72% el comportamiento de la variable tasa de homicidios.  

**Punto 3** Informar qué información da el coeficiente de determinación. 

**Respuesta - Conclusiones (pto 3)** El coeficiente de determinación indica la varianza de la variable dependiente que se explica mediante el modelo seleccionado. Es por esto que permite cuantificar la bondad del modelo para predecir el valor de las observaciones indicando la varianza de la variable que se busca explicar a traves del modelo.   
Es importante tener en cuenta que miesntras mas predictores se seleccionen para contruir el modelo, mayor es el valor que va a tomar el coficiente de determinacion (r2), en este sentido, no es un coeficiente util para comparar modelos con distinta cantidad de predictores, con ese fin debe utilizarle el r2 ajustado que penaliza al r2 de acuerdo a la cantidad de variables predictoras que se incluya en el modelo.  
En el modelo seleccionado se observa que r2 ajustado es de 0.9972 (bondad del ajuste del modelo), es decir, la regresion es estadisticamente significativa.  (**Punto 5**)
 
**Punto 4** Supuestos necesarios para definir la prueba inferencial de los estimadores de los parámeros son:

* Supuesto de linealidad: entre los predictores y la variable dependiente
* Homocedasticidad: varianza constante de los residuos. 
* Normalidad  
* Muestras independientes 

**Punto 6**  Realizar un análisis de los residuos del modelo para evaluar el cumplimiento de los supuestos. Para esto, realizar gráficos de los residuos con el valor predicho. 
 
Muchos de los supuestos del modelo de regresion lineal pueden evaluarse analizando los residuos.

Para el analisis de los residuos se realiza un test de normalidad, se debe comprobar si la distribucion de los valores atipicos se distribuyen de forma normal con media cero. 

```{r}
#Grafico de residuos
ols_plot_resid_qq(modelo_ejer2)
```

Alli vemos que algunos valores se alejan de la normal.

**Punto 7** Analizar la colinealidad de las variables predictoras presentes en la ecuación;

Para el analisis de la multicolinealidad de las variables independientes se va utilizar la funcion ols_vif_tol que a traves de los valores VIF y TOL nos indica cuando las variables independientes que fueron seleccionadas como predictoras en el modelo  tienen o no una fuerte asociación con el resto de los predictores. 

```{r}
diagmulticolinealidad <- ols_vif_tol(modelo_ejer2)
diagmulticolinealidad
```
 
A partir de los valores que arroja la funcion concluimos que no existe multicolinealidad entre las variables seleccionadas por el modelo, en tanto los valores de tolerancia no son menores a 0.1 y los valores VIF no superan a 10.   

**Punto 8**  Analizar la presencia de observaciones atípicas y/o influyentes.

```{r} 
#####  Gráfico de residuos studentizado
ols_plot_resid_stud_fit(modelo_ejer2)
```

Mediante el gráfico de los residuos studentizados, podemos observar que existen dos valores atípicos de la variable dependiente. 

Para analizar la influencia de los outliers del modelo seleccionado, realizamos un grafico que muestra la distancia de Cook para puntos influyentes. De esta manera muestra que observaciones con características de outlier inciden en la estimación de los parámetros. 
```{r}
#Distancia de Cook
ols_plot_cooksd_bar(modelo_ejer2, print_plot = TRUE)
```

Segun el grafico, la observacion 1 pareciera contener también un outlier. Para analizar su influencia sobre el modelo vamos a realizar un grafico dfbetas. 

```{r}
#DFBETAS
ols_plot_dfbetas(modelo_ejer2, print_plot = TRUE)
```

De acuerdo a lo que muestran estos graficos, los DFBETAS del caso 10 de LIC y  el caso 1 de UNEMP y WE se encuentran por fuera de la normal.
Una opcion es ajustar nuestro modelo quitando estos valores atipicos. 

```{r}
Base_SinOutliers = p301[c(-1,-10),]
modelo_SinOutliers = lm(formula = H ~ UNEMP +LIC+ WE,
                      data = Base_SinOutliers)
summary(modelo_SinOutliers)
```

**Respuesta - Conclusiones (pto 8)** Observamos que, al quitar las observaciones outliers, aumenta el R cuadrado ajustado. En tanto, el valor del R2ajustado del primer modelo era  0.9972  y ahora toma el valor de 0.999. Considerando que esta diferencia no es abismal, resulta mas adecuado mantener todas la observaciones para el calculo del modelo. 

---

## Ejercicio 3. Regresión Logística  | Peso al nacer

Consigna:

El bajo peso al nacer, definido por un peso al nacer inferior a 2500 gr., ha sido una preocupación de los médicos durante años debido a que tanto las tasas de mortalidad como la de nacimientos defectuosos son muy altas para los niños con bajo peso al nacer. El comportamiento de la mujer durante el embarazo (incluyendo la dieta, los hábitos tabáquicos y los cuidados prenatales) pueden alterar las chances de un parto de un niño con bajo peso. 

Los datos que se presentan en este ejercicio corresponden a 189 nacimientos de los cuales 59 han resultado en niños con bajo peso. 

El objetivo de este ejercicio es determinar cuáles de las variables presentes en la base de datos que se adjunta son factores de riesgo de bajo peso al nacer.

La base de datos que se presenta (archivo LOWBWT.sav) contiene las siguientes variables:

- ID: Código de identificación 
- LOW: Bajo peso al nacer. (0 = ≥2500 g; 1 = <2500 g) (variable dependiente) 
- AGE: Edad de la madre 
- LWT: Peso de la madre el momento de la última menstruación (en libras) 
- RACE: Raza (1 = White; 2 = Black; 3 = Other) 
- SMOKE: Fumó durante el embarazo (0 = No 1 = Yes) 
- PTL: Antecedentes de embarazos prematuros (0 = None; 1 = One; 2 = Two, etc). 
- HT: Antecedentes de hipertensión arterial (0 = No; 1 = Yes) 
- UI: Irritabilidad uterine (0 = No; 1 = Yes) 
- FTV: Cantidad de consultas obstétricas durante el primer trimestre (0 = None; 1 = One; 2 = Two, etc.) 
- BWT: Peso al nacer del bebé en gramos  
 
**Se requiere construir una ecuación de regresión logística que relacione la variable dicotómica que indica si se trata de un nacimiento con bajo peso al nacer con el resto de las variables que corresponda, y determinar si estas variables son útiles para predecir la variable dependiente**.

1. Calcular el riesgo relativo y los odds ratio de la variable dependiente con todas las variables dicotómicas. Analizar los resultados.

2. Cual es la definición de odds ratio? Qué información suministra y de qué manera puede calcularse utilizando la regresión logística?

3. Calcule los odds ratio de cada una de las variables predictoras con la variable dependiente? Comentar.

4. Realizar una regresión logística múltiple, seleccionando los mejores predictores entre las variables independientes disponibles, utilizando un método de selección automática. Describir el proceso de selección automática utilizado. (Sug. Considerar como probabilidad de entrada 0.10 y de salida del modelo 0.15.)

5. Según el modelo obtenido, cuáles son los principales factores de riesgo del bajo peso y cuál es la magnitud de su efecto?

6. Cuáles son los supuestos necesarios para definir la prueba inferencial de los estimadores de los parámetros?

7. Analizar la bondad del ajuste del modelo obtenido, comentando los indicadores y/o test que considera.

8. Indicar porcentaje de casos bien predichos por el modelo.

Cargamos BD

```{r cargamos BD Ejercicio 3, echo=TRUE} 
PesoAlNacer <- read_sav("C:/Users/cbarbagelata/OneDrive - Obra Social Acción Social de Empresarios Asociación Civil/Escritorio/Camila B/Estadistica II/Final/LOWBWT.sav") 
```
---

### Resolución

**Punto 1** Calcular el riesgo relativo (o probabilidad) y los odds ratio (oportunidad) de la variable dependiente con todas las variables dicotómicas. Analizar los resultados.

En nuestro ejercicio tenemos como variable dependiente: la variable LOW (1=bajo peso al nacer -  0=No tiene bajo peso al nacer) y como posibles variables predictoras: las variables dicotomicas SMOKE (Fumó durante el embarazo, 0=No - 1=Si), HT (Antecedentes de hipertensión arterial, 0=No - 1=Si) y UI (Irritabilidad uterina, 0=No - 1=Yes). 

A los fines de predecir si se trata de un nacimiento con bajo peso al nacer a partir de las variables predictores se requiere construir una modelo de regresión logística. 

Calculo de los odds ratio para cada variable independiente: 
```{r}
#Variable smoke
VarSmoke<-glm(LOW~SMOKE,data=PesoAlNacer,family="binomial")
summary(VarSmoke)
or_glm(data = PesoAlNacer, model = VarSmoke, incr = list(SMOKE=1))
```
La oportunidad de tener un bebé con bajo peso al nacer es de 2.022 mayor en las madres fumadoras. 

```{r}
#Variable HT: Antecedentes de hipertensión arterial
VarHT<-glm(LOW~HT,data=PesoAlNacer,family="binomial")
summary(VarSmoke)
or_glm(data = PesoAlNacer, model = VarHT, incr = list(HT=1))
```
La oportunidad de tener un bebe con bajo peso al nacer es 3.36 veces mayor en una madre con antecedentes de hipertension arterial. 

```{r}
#Variable UI: Irritabilidad uterina
VarUI<-glm(LOW~UI,data=PesoAlNacer,family="binomial")
summary(VarUI)
or_glm(data = PesoAlNacer, model = VarUI, incr = list(UI=1))
```
La oportunidad de tener un bebe con bajo peso al nacer es 2.58 veces mayor en una madre con Irritabilidad uterina.

**Punto 2** ¿Cual es la definición de odds ratio? Qué información suministra y de qué manera puede calcularse utilizando la regresión logística?

El odds ratio es un indicador que se obtiene a partir del cociente entre la cantidad de ocurrencias de un evento sobre la cantidad de no ocurrencias de un evento. De esta manera, nos da la oportunidad de ocurrencia de un evento, en este caso, la probablidad de bajo peso al nacer en presencia o ausencia de otro evento. Asi, es posible cuantificar el efecto de una variable independiente sobre una variable dependiente que queremos explicar. 
En aquellas situaciones en las que al analizar el efecto de una determinada variable independiente obtenemos un odds ratio mayor a 1 significa que ese factor incrementa el riesgo. Mientras que si es igual a 1 significa que no existe efecto de la variable independiente sobre la variable dependiente. En cambio, si nos da un valor menor a 1 significa que la variable independiente tiene efecto pero lo que produce es disminuir el riesgo de ocurrencia del evento.


**Punto 3** Calcule los odds ratio de cada una de las variables predictoras con la variable dependiente. 

Calculo de los odds ratio con los demás predictores:

- AGE: Edad de la madre 
- LWT: Peso de la madre el momento de la última menstruación (en libras) 
- RACE: Raza (1 = White; 2 = Black; 3 = Other) 
- PTL: Antecedentes de embarazos prematuros (0 = None; 1 = One; 2 = Two, etc). 
- FTV: Cantidad de consultas obstétricas durante el primer trimestre (0 = None; 1 = One; 2 = Two, etc.)  

```{r}
#Variable AGE: Edad de la madre 
VarAge <- glm(LOW~AGE,data=PesoAlNacer,family="binomial")
summary(VarAge)
or_glm(data = PesoAlNacer, model = VarAge, incr = list(AGE=10))
```

Al calcular el odds ratio de la variable AGE, incrementándo la edad de la madre en 10 años, nos da un valor de 0.6. Esta relación no es significativa con un p-valor (0.105) mayor a 0.05

```{r}
#Variable LWT:Peso de la madre el momento de la última menstruación (en libras)
VarLWT <- glm(LOW~LWT,data=PesoAlNacer,family="binomial")
summary(VarLWT)
or_glm(data = PesoAlNacer, model = VarLWT, incr = list(LWT=15))
```

En cuanto al peso de la madre al momento de la última menstruación, observamos que cuando éste se incrementa, disminuye el riesgo de tener bebes con bajo peso al nacer. Esta relación es significativa con un p-valor de 0.022.

```{r}
#Variable RACE: Raza (1 = White; 2 = Black; 3 = Other) 
VarRACE<- glm(LOW~RACE,data=PesoAlNacer,family="binomial")
summary(VarRACE)
or_glm(data = PesoAlNacer, model = VarRACE, incr = list(RACE=1))
```

En este caso, la raza  de la madre no afectaría al bajo peso al nacer de los hijos,ya que el valor del p es mayor a 0.05 (0.059613). 

```{r}
#Variable PTL: Antecedentes de embarazos prematuros (0 = None; 1 = One; 2 = Two, etc)
VarPTL<- glm(LOW~PTL,data=PesoAlNacer,family="binomial")
summary(VarPTL)
or_glm(data = PesoAlNacer, model = VarPTL, incr = list(PTL=1))
```

Respecto a la influencia de la variable Antecedentes de embarazos prematuros en la madre frente al nacimiento de hijos con bajo peso al nacer, obtenemos que en aquellas madres con antecedentes tiene un 2.23 mas de probabilidad de tener un hijo con bajo peso al nacer que una madre sin embarazos prematuros previos. El valor del indicador de odds ratio de la variable PTL es estadisticamente significativo (p-value=0.0115). 
 
- FTV: Cantidad de consultas obstétricas durante el primer trimestre 0 = None; 1 = One; 2 = Two, etc.) 

```{r}
#Variable FTV: Cantidad de consultas obstétricas durante el primer trimestre
VarFTV<- glm(LOW~FTV,data=PesoAlNacer,family="binomial")
summary(VarFTV)
or_glm(data = PesoAlNacer, model = VarFTV, incr = list(FTV=1))
```

Respecto al efecto de la Cantidad de consultas obstétricas durante el primer trimestre, dado que el pvalue es mayor a 0,05 concluimos que no es estadisticamente significativa. Es decir, no afecta la ocurrencia del fenomenos de tener hijos con bajo peso al nacer.  

**Punto 4** Realizar una regresión logística múltiple, seleccionando los mejores predictores entre las variables independientes disponibles, utilizando un método de selección automática. Describir el proceso de selección automática utilizado. (Sug. Considerar como probabilidad de entrada 0.10 y de salida del modelo 0.15.)

A los fines de realizar una regresión logística con los mejores predictores entre las variables independientes disponibles aplicamos la funcion stepAIC sobre la salidad de logit. 

```{r}
RegLog <- glm(LOW ~ 1, family = 'binomial', data = PesoAlNacer)
RegLogAuto <- stepAIC(RegLog, scope = list(upper = ~AGE + LWT + factor(RACE) + SMOKE + factor(PTL) + HT + UI + factor(FTV), lower = ~1), direction = c("both"),trace = TRUE,  pent = 0.10, prem = 0.15)
 

```
Segun la seleccion automatica que realiza la funcion, optamos por modelo conformado por seis variables: PTL , LWT , HT , RACE, SMOKE ,UI que posee el AIC de menor valor. 
Creamos un nuevo objeto conformado por las variables que arrojo la funcion de seleccion automatica
```{r}
#Modelo final
ModFinal <- glm(LOW ~ PTL+LWT+HT+factor(RACE)+SMOKE+UI,
             family = binomial, data = PesoAlNacer)
summary(ModFinal)
```
Si observamos los valores p value, la variable PTL y UI no son estadísticamente significativas, por lo cual se procede a eliminarlas del modelo y definirlo nuevamente sin esas variables.

```{r}
ModFinal2 <- glm (LOW ~ LWT + HT + factor(RACE) + SMOKE, family = binomial, data=PesoAlNacer)
summary (ModFinal2)
``` 
**Punto 5** Según el modelo obtenido, cuáles son los principales factores de riesgo del bajo peso y cuál es la magnitud de su efecto? 

Segun el modelo obtenido, los principales factores de riesgo del bajo peso al nacer son el peso de la madre al momento de la última menstruación, los antecedentes de hipertensión arterial, la raza de la madre y haber fumado durante el embarazo. La magnitud de su efecto se obtiene a traves del valor de los Odds Ratio.  

```{r}
OddsRatio(ModFinal2)
```
Por el análisis de los OR podemos decir que, manteniendo, los antecedentes de hipertensión arterial aumenta en un 5.75 las probabilidades de tener un hijo con bajo peso al nacer, mientras que si la madre es de raza negra aumenta en un 3.6 y se de otra raza pero no blanca aumenta en un 2,6 las probabilidades. Respecto a si la madre fumo durante el embarazo aumenta en un 2.9 las probabilidades de tener un hijo con bajo peso al nacer. En cambio, el peso de la madre al momento de la última menstruación disminuye la posibilidad de tener un hijo con bajo peso al nacer.  
 
**Punto 6**  Cuáles son los supuestos necesarios para definir la prueba inferencial de los estimadores de los parámetros?
Los supuestos son: 

- Que la variable dependiente sea dicotómica.
- Que exista poca o nula multicolinealidad.
- Que la relación entre la variable dependiente y los odds ratio sea lineal.  
- Que los valores que  fueron los observados sean indepedientes. 

**Punto 7**  Analizar la bondad del ajuste del modelo obtenido, comentando los indicadores y/o test que considera.
Para analizar la bondad del ajuste del modelo utilizamos los indicadores de deviance y AIC. 